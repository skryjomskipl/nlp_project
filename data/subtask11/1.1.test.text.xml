<?xml version="1.0" encoding="UTF-8" ?>
<doc>

<text id="P03-1068"> <title>Towards a Resource for Lexical Semantics: A Large German Corpus with Extensive Semantic Annotation</title> <abstract> We describe the ongoing construction of a large, <entity id="P03-1068.1">semantically annotated corpus</entity> resource as reliable basis for the large-scale <entity id="P03-1068.2">acquisition of word-semantic information</entity> , e.g. the construction of <entity id="P03-1068.3">domain-independent lexica</entity> . The backbone of the <entity id="P03-1068.4">annotation</entity> are <entity id="P03-1068.5">semantic roles</entity> in the <entity id="P03-1068.6">frame semantics paradigm</entity> . We report experiences and evaluate the <entity id="P03-1068.7">annotated data</entity> from the first project stage. On this basis, we discuss the problems of <entity id="P03-1068.8">vagueness</entity> and <entity id="P03-1068.9">ambiguity</entity> in <entity id="P03-1068.10">semantic annotation</entity> . </abstract>


</text>

<text id="P03-1070"> <title>Towards a Model of Face-to-Face Grounding</title> <abstract> We investigate the <entity id="P03-1070.1">verbal and nonverbal means</entity> for <entity id="P03-1070.2">grounding</entity> , and propose a design for <entity id="P03-1070.3">embodied conversational agents</entity> that relies on both kinds of <entity id="P03-1070.4">signals</entity> to establish <entity id="P03-1070.5">common ground</entity> in <entity id="P03-1070.6">human-computer interaction</entity> . We analyzed <entity id="P03-1070.7">eye gaze</entity> , <entity id="P03-1070.8">head nods</entity> and <entity id="P03-1070.9">attentional focus</entity> in the context of a <entity id="P03-1070.10">direction-giving task</entity> . The distribution of <entity id="P03-1070.11">nonverbal behaviors</entity> differed depending on the type of <entity id="P03-1070.12">dialogue move</entity> being grounded, and the overall pattern reflected a monitoring of lack of <entity id="P03-1070.13">negative feedback</entity> . Based on these results, we present an <entity id="P03-1070.14">ECA</entity> that uses <entity id="P03-1070.15">verbal and nonverbal grounding acts</entity> to update <entity id="P03-1070.16">dialogue state</entity> . </abstract>



</text>

<text id="P03-2036"> <title>Comparison between CFG filtering techniques for LTAG and HPSG</title> <abstract> An empirical comparison of <entity id="P03-2036.1">CFG filtering techniques</entity> for <entity id="P03-2036.2">LTAG</entity> and <entity id="P03-2036.3">HPSG</entity> is presented. We demonstrate that an approximation of <entity id="P03-2036.4">HPSG</entity> produces a more effective <entity id="P03-2036.5">CFG filter</entity> than that of <entity id="P03-2036.6">LTAG</entity> . We also investigate the reason for that difference. </abstract>


</text>

<text id="C04-1035"> <title>Classifying Ellipsis in Dialogue: A Machine Learning Approach</title> <abstract> This paper presents a <entity id="C04-1035.1">machine learning</entity> approach to bare <entity id="C04-1035.2">sluice disambiguation</entity> in <entity id="C04-1035.3">dialogue</entity> . We extract a set of <entity id="C04-1035.4">heuristic principles</entity> from a corpus-based sample and formulate them as <entity id="C04-1035.5">probabilistic Horn clauses</entity> . We then use the <entity id="C04-1035.6">predicates</entity> of such <entity id="C04-1035.7">clauses</entity> to create a set of <entity id="C04-1035.8">domain independent features</entity> to annotate an input <entity id="C04-1035.9">dataset</entity> , and run two different <entity id="C04-1035.10">machine learning algorithms</entity> : <entity id="C04-1035.11">SLIPPER</entity> , a <entity id="C04-1035.12">rule-based learning algorithm</entity> , and <entity id="C04-1035.13">TiMBL</entity> , a <entity id="C04-1035.14">memory-based system</entity> . Both <entity id="C04-1035.15">learners</entity> perform well, yielding similar <entity id="C04-1035.16">success rates</entity> of approx 90% . The results show that the <entity id="C04-1035.17">features</entity> in terms of which we formulate our <entity id="C04-1035.18">heuristic principles</entity> have significant <entity id="C04-1035.19">predictive power</entity> , and that <entity id="C04-1035.20">rules</entity> that closely resemble our <entity id="C04-1035.21">Horn clauses</entity> can be learnt automatically from these <entity id="C04-1035.22">features</entity> . </abstract>


</text>

<text id="C04-1036"> <title>Feature Vector Quality and Distributional Similarity</title> <abstract> We suggest a new goal and evaluation criterion for <entity id="C04-1036.1">word similarity measures</entity> . The new criterion - <entity id="C04-1036.2">meaning-entailing substitutability</entity> - fits the needs of <entity id="C04-1036.3">semantic-oriented NLP applications</entity> and can be evaluated directly (independent of an <entity id="C04-1036.4">application</entity> ) at a good level of <entity id="C04-1036.5">human agreement</entity> . Motivated by this semantic criterion we analyze the empirical quality of <entity id="C04-1036.6">distributional word feature vectors</entity> and its impact on <entity id="C04-1036.7">word similarity</entity> results, proposing an objective <entity id="C04-1036.8">measure</entity> for evaluating <entity id="C04-1036.9">feature vector</entity> quality. Finally, a novel <entity id="C04-1036.10">feature weighting and selection function</entity> is presented, which yields superior <entity id="C04-1036.11">feature vectors</entity> and better <entity id="C04-1036.12">word similarity</entity> performance. </abstract>


</text>

<text id="C04-1068"> <title>Filtering Speaker-Specific Words from Electronic Discussions</title> <abstract> The work presented in this paper is the first step in a project which aims to cluster and summarise <entity id="C04-1068.1">electronic discussions</entity> in the context of <entity id="C04-1068.2">help-desk applications</entity> . The eventual objective of this project is to use these <entity id="C04-1068.3">summaries</entity> to assist <entity id="C04-1068.4">help-desk users and operators</entity> . In this paper, we identify <entity id="C04-1068.5">features</entity> of <entity id="C04-1068.6">electronic discussions</entity> that influence the <entity id="C04-1068.7">clustering process</entity> , and offer a <entity id="C04-1068.8">filtering mechanism</entity> that removes undesirable influences. We tested the <entity id="C04-1068.9">clustering and filtering processes</entity> on <entity id="C04-1068.10">electronic newsgroup discussions</entity> , and evaluated their performance by means of two experiments: coarse-level <entity id="C04-1068.11">clustering</entity> and simple <entity id="C04-1068.12">information retrieval</entity> . Our evaluation shows that our <entity id="C04-1068.13">filtering mechanism</entity> has a significant positive effect on both tasks. </abstract>


</text>

<text id="C04-1080"> <title>Part of Speech Tagging in Context</title> <abstract> We present a new <entity id="C04-1080.1">HMM tagger</entity> that exploits <entity id="C04-1080.2">context</entity> on both sides of a <entity id="C04-1080.3">word</entity> to be tagged, and evaluate it in both the <entity id="C04-1080.4">unsupervised and supervised case</entity> . Along the way, we present the first comprehensive comparison of <entity id="C04-1080.5">unsupervised methods for part-of-speech tagging</entity> , noting that published results to date have not been comparable across <entity id="C04-1080.6">corpora</entity> or <entity id="C04-1080.7">lexicons</entity> . Observing that the quality of the <entity id="C04-1080.8">lexicon</entity> greatly impacts the <entity id="C04-1080.9">accuracy</entity> that can be achieved by the algorithms, we present a method of <entity id="C04-1080.10">HMM training</entity> that improves <entity id="C04-1080.11">accuracy</entity> when training of <entity id="C04-1080.12">lexical probabilities</entity> is unstable. Finally, we show how this new <entity id="C04-1080.13">tagger</entity> achieves state-of-the-art results in a <entity id="C04-1080.14">supervised, non-training intensive framework</entity> . </abstract>


</text>

<text id="C04-1096"> <title>Generation of Relative Referring Expressions based on Perceptual Grouping</title> <abstract> Past work of <entity id="C04-1096.1">generating referring expressions</entity> mainly utilized <entity id="C04-1096.2">attributes</entity> of <entity id="C04-1096.3">objects</entity> and <entity id="C04-1096.4">binary relations</entity> between <entity id="C04-1096.5">objects</entity> . However, such an approach does not work well when there is no distinctive <entity id="C04-1096.6">attribute</entity> among <entity id="C04-1096.7">objects</entity> . To overcome this limitation, this paper proposes a method utilizing the perceptual groups of <entity id="C04-1096.8">objects</entity> and <entity id="C04-1096.9">n-ary relations</entity> among them. The key is to identify groups of <entity id="C04-1096.10">objects</entity> that are naturally recognized by <entity id="C04-1096.11">humans</entity> . We conducted <entity id="C04-1096.12">psychological experiments</entity> with 42 subjects to collect <entity id="C04-1096.13">referring expressions</entity> in such situations, and built a <entity id="C04-1096.14">generation algorithm</entity> based on the results. The evaluation using another 23 subjects showed that the proposed method could effectively generate proper <entity id="C04-1096.15">referring expressions</entity> . </abstract>


</text>

<text id="C04-1103"> <title>Direct Orthographical Mapping for Machine Transliteration</title> <abstract> <entity id="C04-1103.1">Machine transliteration/back-transliteration</entity> plays an important role in many <entity id="C04-1103.2">multilingual speech and language applications</entity> . In this paper, a novel framework for <entity id="C04-1103.3">machine transliteration/back transliteration</entity> that allows us to carry out <entity id="C04-1103.4">direct orthographical mapping (DOM)</entity> between two different <entity id="C04-1103.5">languages</entity> is presented. Under this framework, a <entity id="C04-1103.6">joint source-channel transliteration model</entity> , also called <entity id="C04-1103.7">n-gram transliteration model (ngram TM)</entity> , is further proposed to model the <entity id="C04-1103.8">transliteration process</entity> . We evaluate the proposed methods through several <entity id="C04-1103.9">transliteration/back transliteration</entity> experiments for <entity id="C04-1103.10">English/Chinese and English/Japanese language pairs</entity> . Our study reveals that the proposed method not only reduces an extensive system development effort but also improves the <entity id="C04-1103.11">transliteration accuracy</entity> significantly. </abstract>


</text>

<text id="C04-1106"> <title>Lower and higher estimates of the number of &amp;quot;true analogies&amp;quot; between sentences contained in a large multilingual corpus</title> <abstract> The reality of <entity id="C04-1106.1">analogies between words</entity> is refuted by noone (e.g., I walked is to to walk as I laughed is to to laugh, noted I walked : to walk :: I laughed : to laugh). But <entity id="C04-1106.2">computational linguists</entity> seem to be quite dubious about <entity id="C04-1106.3">analogies between sentences</entity> : they would not be enough numerous to be of any use. We report experiments conducted on a <entity id="C04-1106.4">multilingual corpus</entity> to estimate the number of <entity id="C04-1106.5">analogies</entity> among the <entity id="C04-1106.6">sentences</entity> that it contains. We give two estimates, a lower one and a higher one. As an <entity id="C04-1106.7">analogy</entity> must be valid on the level of <entity id="C04-1106.8">form</entity> as well as on the level of <entity id="C04-1106.9">meaning</entity> , we relied on the idea that <entity id="C04-1106.10">translation</entity> should preserve <entity id="C04-1106.11">meaning</entity> to test for similar <entity id="C04-1106.12">meanings</entity> . </abstract>

</text>
</doc>
