<?xml version="1.0" encoding="UTF-8"?>
<doc>




<text id="L08-1450"><title>
A LAF/GrAF <entity id="L08-1450.1">based</entity> Encoding <entity id="L08-1450.2">Scheme</entity> for underspecified Representations of <entity id="L08-1450.3">syntactic</entity> Annotations.
</title><abstract><entity id="L08-1450.4">Data</entity> <entity id="L08-1450.5">models</entity> and encoding <entity id="L08-1450.6">formats</entity> for syntactically annotated <entity id="L08-1450.7">text</entity> <entity id="L08-1450.8">corpora</entity> need to <entity id="L08-1450.9">deal</entity> with <entity id="L08-1450.10">syntactic</entity> <entity id="L08-1450.11">ambiguity</entity>; underspecified <entity id="L08-1450.12">representations</entity> are particularly well suited for the <entity id="L08-1450.13">representation</entity> of ambiguous<entity id="L08-1450.14">data</entity> because they allow for high informational <entity id="L08-1450.15">efficiency</entity>. We discuss the <entity id="L08-1450.16">issue</entity> of being informationally efficient, and the trade-off between efficient encoding of linguistic annotations and complete <entity id="L08-1450.17">documentation</entity> of <entity id="L08-1450.18">linguistic analyses</entity>. The <entity id="L08-1450.19">main</entity> <entity id="L08-1450.20">topic</entity> of this article is a<entity id="L08-1450.21">data</entity> <entity id="L08-1450.22">model</entity> and an encoding <entity id="L08-1450.23">scheme</entity> <entity id="L08-1450.24">based</entity> on LAF/GrAF ( <BIBLIO><entity id="L08-1450.25">Ide</entity> and  Romary, 2006</BIBLIO> ; <BIBLIO><entity id="L08-1450.26">Ide</entity> and  Suderman, 2007</BIBLIO> ) which <entity id="L08-1450.27">provides</entity> a flexible <entity id="L08-1450.28">framework</entity> for encoding underspecified <entity id="L08-1450.29">representations</entity>. We show how a set of <entity id="L08-1450.30">dependency structures</entity> and a set of <entity id="L08-1450.31">TiGer</entity> graphs ( <BIBLIO>Brants et al., 2002</BIBLIO> ) representing the readings of an ambiguous <entity id="L08-1450.32">sentence</entity> can be encoded, and we discuss <entity id="L08-1450.33">basic</entity> <entity id="L08-1450.34">issues</entity> in <entity id="L08-1450.35">querying</entity> <entity id="L08-1450.36">corpora</entity> which are encoded using the <entity id="L08-1450.37">framework</entity> presented here.
</abstract>


</text>

<text id="L08-1459"><title>
A <entity id="L08-1459.1">Study</entity> of Parentheticals in <entity id="L08-1459.2">Discourse</entity> <entity id="L08-1459.3">Corpora</entity> - Implications for NLG <entity id="L08-1459.4">Systems</entity></title><abstract>
This <entity id="L08-1459.5">paper</entity> presents a <entity id="L08-1459.6">corpus</entity> <entity id="L08-1459.7">study</entity> of parenthetical <entity id="L08-1459.8">constructions</entity> in two different <entity id="L08-1459.9">corpora</entity>: the Penn <entity id="L08-1459.10">Discourse</entity> Treebank (PDTB, (PDTB- <BIBLIO>Group, 2008</BIBLIO> )) and the RST <entity id="L08-1459.11">Discourse</entity> Treebank ( <BIBLIO>Carlson et al., 2001</BIBLIO> ). The <entity id="L08-1459.12">motivation</entity> for the <entity id="L08-1459.13">study</entity> is to <entity id="L08-1459.14">gain</entity> a better <entity id="L08-1459.15">understanding</entity> of the rhetorical <entity id="L08-1459.16">properties</entity> of parentheticals in <entity id="L08-1459.17">order</entity> to enable a <entity id="L08-1459.18">natural language generation system</entity> to produce parentheticals as <entity id="L08-1459.19">part</entity> of a rhetorically well-formed <entity id="L08-1459.20">output</entity>. We argue that there is a <entity id="L08-1459.21">correlation</entity> between <entity id="L08-1459.22">syntactic</entity> and rhetorical <entity id="L08-1459.23">types</entity> of parentheticals and establish two <entity id="L08-1459.24">main</entity> <entity id="L08-1459.25">categories</entity>: elaboration/<entity id="L08-1459.26">expansion-type</entity> <entity id="L08-1459.27">NP-modifier</entity> parentheticals and non-elaboration/<entity id="L08-1459.28">expansion-type</entity> VP- or S-<entity id="L08-1459.29">modifier</entity> parentheticals. We show several <entity id="L08-1459.30">strategies</entity> for <entity id="L08-1459.31">extracting</entity> these from the two <entity id="L08-1459.32">corpora</entity> and discuss how the seemingly contradictory <entity id="L08-1459.33">results</entity> obtained can be reconciled in light of the rhetorical and <entity id="L08-1459.34">syntactic</entity> <entity id="L08-1459.35">properties</entity> of parentheticals as well as the <entity id="L08-1459.36">decisions</entity> taken in the annotation <entity id="L08-1459.37">guidelines</entity>.
</abstract>


</text>

<text id="I05-2027"><title>
<entity id="I05-2027.1">Machine Learning Approach</entity> to Augmenting <entity id="I05-2027.2">News</entity> <entity id="I05-2027.3">Headline</entity> <entity id="I05-2027.4">Generation</entity>
</title><abstract>In this <entity id="I05-2027.5">paper</entity>, we present the HybridTrim <entity id="I05-2027.6">system</entity> which uses a <entity id="I05-2027.7">machine</entity> learning <entity id="I05-2027.8">technique</entity> to combine linguistic, <entity id="I05-2027.9">statistical</entity> and positional <entity id="I05-2027.10">information</entity> to identify <entity id="I05-2027.11">topic</entity> labels for <entity id="I05-2027.12">headlines</entity> in a <entity id="I05-2027.13">text</entity>. We compare our <entity id="I05-2027.14">system</entity> with the Topiary <entity id="I05-2027.15">system</entity> which, in <entity id="I05-2027.16">contrast</entity>, uses a <entity id="I05-2027.17">statistical</entity> <entity id="I05-2027.18">learning approach</entity> to finding <entity id="I05-2027.19">topic</entity> descriptors for <entity id="I05-2027.20">headlines</entity>. The Topiary <entity id="I05-2027.21">system</entity>, <entity id="I05-2027.22">developed</entity> at the <entity id="I05-2027.23">University</entity> of Maryland with BBN, was the top performing <entity id="I05-2027.24">headline</entity> <entity id="I05-2027.25">generation system</entity> at DUC 2004. Topiary-style <entity id="I05-2027.26">headlines</entity> consist of a <entity id="I05-2027.27">number</entity> of general <entity id="I05-2027.28">topic</entity> labels followed by a compressed <entity id="I05-2027.29">version</entity> of the lead <entity id="I05-2027.30">sentence</entity> of a <entity id="I05-2027.31">news</entity> story. The Topiary <entity id="I05-2027.32">system</entity> uses a <entity id="I05-2027.33">statistical</entity> <entity id="I05-2027.34">learning approach</entity> to finding <entity id="I05-2027.35">topic</entity> labels. The <entity id="I05-2027.36">performance</entity> of these <entity id="I05-2027.37">systems</entity> is <entity id="I05-2027.38">evaluated</entity> using the <entity id="I05-2027.39">ROUGE</entity> <entity id="I05-2027.40">evaluation</entity> <entity id="I05-2027.41">suite</entity> on the DUC 2004 <entity id="I05-2027.42">news</entity> stories <entity id="I05-2027.43">collection</entity>.
</abstract>


</text>

<text id="N03-1014"><title>
Inducing History Representations For Broad <entity id="N03-1014.1">Coverage</entity> <entity id="N03-1014.2">Statistical</entity> <entity id="N03-1014.3">Parsing</entity></title><abstract>
We present a <entity id="N03-1014.4">neural network</entity> <entity id="N03-1014.5">method</entity> for inducing <entity id="N03-1014.6">representations</entity> of <entity id="N03-1014.7">parse</entity> histories and using these history <entity id="N03-1014.8">representations</entity> to estimate the <entity id="N03-1014.9">probabilities</entity> needed by a <entity id="N03-1014.10">statistical</entity> left-corner <entity id="N03-1014.11">parser</entity>. The <entity id="N03-1014.12">resulting</entity> <entity id="N03-1014.13">statistical</entity> <entity id="N03-1014.14">parser</entity> achieves <entity id="N03-1014.15">performance</entity> (89.1% F-measure) on the <entity id="N03-1014.16">Penn Treebank</entity> which is only 0.6% below the best <entity id="N03-1014.17">current</entity> <entity id="N03-1014.18">parser</entity> for this <entity id="N03-1014.19">task</entity>, despite using a smaller <entity id="N03-1014.20">vocabulary</entity> <entity id="N03-1014.21">size</entity> and less prior <entity id="N03-1014.22">linguistic knowledge</entity>. Crucial to this <entity id="N03-1014.23">success</entity> is the use of structurally determined soft <entity id="N03-1014.24">biases</entity> in inducing the <entity id="N03-1014.25">representation</entity> of the <entity id="N03-1014.26">parse</entity> history, and no use of hard <entity id="N03-1014.27">independence</entity> <entity id="N03-1014.28">assumptions</entity>.
</abstract>


</text>

<text id="N03-2021"><title><entity id="N03-2021.1">Precision</entity> And <entity id="N03-2021.2">Recall</entity> Of <entity id="N03-2021.3">Machine Translation</entity></title>
<abstract><entity id="N03-2021.4">Machine translation</entity> can be <entity id="N03-2021.5">evaluated</entity> using <entity id="N03-2021.6">precision</entity>, <entity id="N03-2021.7">recall</entity>, and the F-measure. These <entity id="N03-2021.8">standard</entity> measures have significantly higher <entity id="N03-2021.9">correlation</entity> with human <entity id="N03-2021.10">judgments</entity> than recently <entity id="N03-2021.11">proposed</entity> <entity id="N03-2021.12">alternatives</entity>. More importantly, the <entity id="N03-2021.13">standard</entity> measures have an intuitive <entity id="N03-2021.14">interpretation</entity>, which can facilitate <entity id="N03-2021.15">insights</entity> into how <entity id="N03-2021.16">MT systems</entity> might be <entity id="N03-2021.17">improved</entity>. The relevant <entity id="N03-2021.18">software</entity> is publicly available.
</abstract>


</text>

<text id="N06-1042"><title><entity id="N06-1042.1">Learning</entity> Morphological <entity id="N06-1042.2">Disambiguation</entity> Rules For Turkish
</title><abstract>
In this <entity id="N06-1042.3">paper</entity>, we present a <entity id="N06-1042.4">rule</entity> <entity id="N06-1042.5">based</entity> <entity id="N06-1042.6">model</entity> for morphological <entity id="N06-1042.7">disambiguation</entity> of Turkish. The <entity id="N06-1042.8">rules</entity> are <entity id="N06-1042.9">generated</entity> by a novel <entity id="N06-1042.10">decision</entity> <entity id="N06-1042.11">list</entity> learning <entity id="N06-1042.12">algorithm</entity> using supervised <entity id="N06-1042.13">training</entity>. Morphological <entity id="N06-1042.14">ambiguity</entity> (e.g. lives = live+s or life+s) is a <entity id="N06-1042.15">challenging</entity> <entity id="N06-1042.16">problem</entity> for agglutinative <entity id="N06-1042.17">languages</entity> like Turkish where close to half of the <entity id="N06-1042.18">words</entity> in running <entity id="N06-1042.19">text</entity> are morphologically ambiguous. Furthermore, it is possible for a <entity id="N06-1042.20">word</entity> to take an unlimited <entity id="N06-1042.21">number</entity> of <entity id="N06-1042.22">suffixes</entity>, therefore the <entity id="N06-1042.23">number</entity> of possible morphological <entity id="N06-1042.24">tags</entity> is unlimited. We attempted to cope with these <entity id="N06-1042.25">problems</entity> by <entity id="N06-1042.26">training</entity> a separate <entity id="N06-1042.27">model</entity> for each of the 126 <entity id="N06-1042.28">morphological features</entity> recognized by the morphological <entity id="N06-1042.29">analyzer</entity>. The <entity id="N06-1042.30">resulting</entity> <entity id="N06-1042.31">decision</entity> <entity id="N06-1042.32">lists</entity> independently vote on each of the potential <entity id="N06-1042.33">parses</entity> of a <entity id="N06-1042.34">word</entity> and the final <entity id="N06-1042.35">parse</entity> is selected <entity id="N06-1042.36">based</entity> on our <entity id="N06-1042.37">confidence</entity> on these votes. The <entity id="N06-1042.38">accuracy</entity> of our <entity id="N06-1042.39">model</entity> (96%) is slightly above the best previously <entity id="N06-1042.40">reported</entity> <entity id="N06-1042.41">results</entity> which use <entity id="N06-1042.42">statistical models</entity>. For <entity id="N06-1042.43">comparison</entity>, when we <entity id="N06-1042.44">train</entity> a single <entity id="N06-1042.45">decision</entity> <entity id="N06-1042.46">list</entity> on full <entity id="N06-1042.47">tags</entity> instead of using separate <entity id="N06-1042.48">models</entity> on each <entity id="N06-1042.49">feature</entity> we get 91% <entity id="N06-1042.50">accuracy</entity>.
</abstract>


</text>

<text id="M92-1018"><title>
SRA SOLOMON: MUC-4 <entity id="M92-1018.1">Test</entity> <entity id="M92-1018.2">Results</entity> And <entity id="M92-1018.3">Analysis</entity></title><abstract>
In this <entity id="M92-1018.4">paper</entity>, we <entity id="M92-1018.5">report</entity> SRA's <entity id="M92-1018.6">results</entity> on the MUC-4 <entity id="M92-1018.7">task</entity> and describe how we <entity id="M92-1018.8">trained</entity> our <entity id="M92-1018.9">natural language processing system</entity> for MUC-4. We also <entity id="M92-1018.10">report</entity> on what worked, what didn't work, and lessons learned. Our MUC-4 <entity id="M92-1018.11">system</entity> embeds the SOLOMON <entity id="M92-1018.12">knowledge-based</entity> NLP shell which is <entity id="M92-1018.13">designed</entity> for both and We are currently using SOLOMON for a Spanish and <entity id="M92-1018.14">Japanese</entity> <entity id="M92-1018.15">text</entity> <entity id="M92-1018.16">understanding</entity> <entity id="M92-1018.17">project</entity> in a different <entity id="M92-1018.18">domain</entity>. Although this was our first year participating in MUC, we have built and are currently building other<entity id="M92-1018.19">data</entity> <entity id="M92-1018.20">extraction systems</entity>.
</abstract>


</text>

<text id="E95-1014"><title><entity id="E95-1014.1">Corpus-</entity><entity id="E95-1014.2">Based</entity> <entity id="E95-1014.3">Method</entity> For <entity id="E95-1014.4">Automatic</entity> <entity id="E95-1014.5">Identification</entity> Of <entity id="E95-1014.6">Support</entity> Verbs For Nominalizations
</title><abstract>
Nominalization is a highly productive <entity id="E95-1014.7">phenomena</entity> in most <entity id="E95-1014.8">languages</entity>. The <entity id="E95-1014.9">process</entity> of nominalization ejects a <entity id="E95-1014.10">verb</entity> from its <entity id="E95-1014.11">syntactic</entity> <entity id="E95-1014.12">role</entity> into a nominal position. The original <entity id="E95-1014.13">verb</entity> is often replaced by a semantically emptied <entity id="E95-1014.14">support</entity> <entity id="E95-1014.15">verb</entity> (e.g., make a <entity id="E95-1014.16">proposal</entity>).
</abstract>


</text>

<text id="A00-1030"><title>
Aggressive <entity id="A00-1030.1">Morphology</entity> For <entity id="A00-1030.2">Robust</entity> <entity id="A00-1030.3">Lexical</entity> <entity id="A00-1030.4">Coverage</entity></title><abstract>
This <entity id="A00-1030.5">paper</entity> describes an <entity id="A00-1030.6">approach</entity> to <entity id="A00-1030.7">providing</entity> <entity id="A00-1030.8">lexical information</entity> for <entity id="A00-1030.9">natural language processing</entity> in unrestricted <entity id="A00-1030.10">domains</entity>. A <entity id="A00-1030.11">system</entity> of approximately 1200 morphological <entity id="A00-1030.12">rules</entity> is used to extend a <entity id="A00-1030.13">core</entity> <entity id="A00-1030.14">lexicon</entity> of 39,000 <entity id="A00-1030.15">words</entity> to <entity id="A00-1030.16">provide</entity> <entity id="A00-1030.17">lexical</entity> <entity id="A00-1030.18">coverage</entity> that exceeds that of a <entity id="A00-1030.19">lexicon</entity> of 80,000 <entity id="A00-1030.20">words</entity> or 150,000 <entity id="A00-1030.21">word</entity> <entity id="A00-1030.22">forms</entity>. The morphological <entity id="A00-1030.23">system</entity> is described, and <entity id="A00-1030.24">lexical</entity> <entity id="A00-1030.25">coverage</entity> is <entity id="A00-1030.26">evaluated</entity> for random <entity id="A00-1030.27">words</entity> chosen from a previously unanalyzed <entity id="A00-1030.28">corpus</entity>.
</abstract>


</text>

<text id="A00-2029"><title>
Predicting <entity id="A00-2029.1">Automatic Speech Recognition</entity> <entity id="A00-2029.2">Performance</entity> Using Prosodic Cues
</title><abstract>
In spoken <entity id="A00-2029.3">dialogue systems</entity>, it is important for a <entity id="A00-2029.4">system</entity> to know how likely a <entity id="A00-2029.5">speech recognition</entity> <entity id="A00-2029.6">hypothesis</entity> is to be correct, so it can reprompt for fresh <entity id="A00-2029.7">input</entity>, or, in <entity id="A00-2029.8">cases</entity> where many <entity id="A00-2029.9">errors</entity> have occurred, change its <entity id="A00-2029.10">interaction</entity> <entity id="A00-2029.11">strategy</entity> or switch the caller to a human attendant. We have discovered prosodie <entity id="A00-2029.12">features</entity> which more accurately predict when a <entity id="A00-2029.13">recognition</entity> <entity id="A00-2029.14">hypothesis</entity> contains a <entity id="A00-2029.15">word</entity> <entity id="A00-2029.16">error</entity> than the acoustic <entity id="A00-2029.17">confidence</entity> score <entity id="A00-2029.18">thresholds</entity> traditionally used in <entity id="A00-2029.19">automatic speech recognition</entity>. We present analytic <entity id="A00-2029.20">results</entity> indicating that there are significant prosodie <entity id="A00-2029.21">differences</entity> between correctly and incorrectly recognized turns.
</abstract>


</text>

<text id="H92-1099"><title><entity id="H92-1099.1">Evaluating</entity> The Use Of Prosodic <entity id="H92-1099.2">Information</entity> In <entity id="H92-1099.3">Speech Recognition</entity> And <entity id="H92-1099.4">Understanding</entity></title><abstract>
The <entity id="H92-1099.5">goal</entity> of this <entity id="H92-1099.6">project</entity> is to investigate the use of different <entity id="H92-1099.7">levels</entity> of prosodie <entity id="H92-1099.8">information</entity> in <entity id="H92-1099.9">speech recognition</entity> and <entity id="H92-1099.10">understanding</entity>. In particular, the <entity id="H92-1099.11">current</entity> <entity id="H92-1099.12">focus</entity> of the work is the use of prosodie <entity id="H92-1099.13">phrase</entity> <entity id="H92-1099.14">boundary</entity> <entity id="H92-1099.15">information</entity> in <entity id="H92-1099.16">parsing</entity>. The <entity id="H92-1099.17">research</entity> involves determining a <entity id="H92-1099.18">representation</entity> of prosodie <entity id="H92-1099.19">information</entity> suitable for use in a <entity id="H92-1099.20">speech understanding system</entity>, <entity id="H92-1099.21">developing</entity> reliable <entity id="H92-1099.22">algorithms</entity> for <entity id="H92-1099.23">detection</entity> of the prosodie <entity id="H92-1099.24">cues</entity> in <entity id="H92-1099.25">speech</entity>, investigating <entity id="H92-1099.26">architectures</entity> for integrating prosodie <entity id="H92-1099.27">cues</entity> in a <entity id="H92-1099.28">parser</entity>, and <entity id="H92-1099.29">evaluating</entity> the potential <entity id="H92-1099.30">improvements</entity> of <entity id="H92-1099.31">prosody</entity> in the <entity id="H92-1099.32">context</entity> of the SRI <entity id="H92-1099.33">Spoken Language System</entity>. This <entity id="H92-1099.34">research</entity> is sponsored jointly by DARPA and NSF.
</abstract>


</text>

<text id="H93-1048"><title><entity id="H93-1048.1">Prediction</entity> Of Lexicalized <entity id="H93-1048.2">Tree</entity> Fragments In <entity id="H93-1048.3">Text</entity></title><abstract>
There is a <entity id="H93-1048.4">mismatch</entity> between the <entity id="H93-1048.5">distribution</entity> of <entity id="H93-1048.6">information</entity> in <entity id="H93-1048.7">text</entity>, and a <entity id="H93-1048.8">variety</entity> of grammatical <entity id="H93-1048.9">formalisms</entity> for describing it, <entity id="H93-1048.10">including</entity> ngrams, <entity id="H93-1048.11">context-free</entity> grammars, and <entity id="H93-1048.12">dependency grammars</entity>. Rather than adding <entity id="H93-1048.13">probabilities</entity> to existing grammars, it is <entity id="H93-1048.14">proposed</entity> to collect the <entity id="H93-1048.15">distributions</entity> of flexibly <entity id="H93-1048.16">sized</entity> <entity id="H93-1048.17">partial</entity> <entity id="H93-1048.18">trees</entity>. These can be used to enhance an ngram <entity id="H93-1048.19">model</entity>, and in analogical <entity id="H93-1048.20">parsing</entity>.
</abstract>


</text>

<text id="H93-1060"><title>
The COMLEX <entity id="H93-1060.1">Syntax</entity> <entity id="H93-1060.2">Project</entity></title><abstract>
"<entity id="H93-1060.3">Developing</entity> more shareable <entity id="H93-1060.4">resources</entity> to <entity id="H93-1060.5">support</entity> <entity id="H93-1060.6">natural language</entity> <entity id="H93-1060.7">analysis</entity> will make it easier and cheaper to create new <entity id="H93-1060.8">language processing</entity> <entity id="H93-1060.9">applications</entity> and to <entity id="H93-1060.10">support</entity> <entity id="H93-1060.11">research</entity> in <entity id="H93-1060.12">computational linguistics</entity>. One <entity id="H93-1060.13">natural</entity> <entity id="H93-1060.14">candidate</entity> for such a <entity id="H93-1060.15">resource</entity> is a <entity id="H93-1060.16">broad-coverage</entity> <entity id="H93-1060.17">dictionary</entity>, since the work <entity id="H93-1060.18">required</entity> to create such a <entity id="H93-1060.19">dictionary</entity> is large but there is general <entity id="H93-1060.20">agreement</entity> on at least some of the <entity id="H93-1060.21">information</entity> to be <entity id="H93-1060.22">recorded</entity> for each <entity id="H93-1060.23">word</entity>. The Linguistic <entity id="H93-1060.24">Data</entity> Consortium has begun an <entity id="H93-1060.25">effort</entity> to create several such <entity id="H93-1060.26">lexical resources</entity>, under the rubric ""COMLEX"" (<entity id="H93-1060.27">COMmon</entity> <entity id="H93-1060.28">LEXicon</entity>); one of these <entity id="H93-1060.29">projects</entity> is the COMLEX <entity id="H93-1060.30">Syntax</entity> <entity id="H93-1060.31">Project</entity>. The <entity id="H93-1060.32">goal</entity> of the COMLEX <entity id="H93-1060.33">Syntax</entity> <entity id="H93-1060.34">Project</entity> is to create a <entity id="H93-1060.35">moderately-broad-coverage</entity> shareable <entity id="H93-1060.36">dictionary</entity> containing the <entity id="H93-1060.37">syntactic features</entity> of <entity id="H93-1060.38">English</entity> <entity id="H93-1060.39">words</entity>, intended for <entity id="H93-1060.40">automatic</entity> <entity id="H93-1060.41">language analysis</entity>. We are initially aiming for a <entity id="H93-1060.42">dictionary</entity> of 35,000 to 40,000 <entity id="H93-1060.43">base</entity> <entity id="H93-1060.44">forms</entity>, although this of course may be enlarged if the initial <entity id="H93-1060.45">effort</entity> is positively received. The <entity id="H93-1060.46">dictionary</entity> should <entity id="H93-1060.47">include</entity> detailed <entity id="H93-1060.48">syntactic</entity> <entity id="H93-1060.49">specifications</entity>, particularly for subcategorization; our intent is to <entity id="H93-1060.50">provide</entity> sufficient <entity id="H93-1060.51">detail</entity> so that the <entity id="H93-1060.52">information</entity> <entity id="H93-1060.53">required</entity> by a <entity id="H93-1060.54">number</entity> of major <entity id="H93-1060.55">English</entity> <entity id="H93-1060.56">analyzers</entity> can be automatically derived from the <entity id="H93-1060.57">information</entity> we <entity id="H93-1060.58">provide</entity>. As with other Linguistic <entity id="H93-1060.59">Data</entity> Consortium <entity id="H93-1060.60">resources</entity>, our intent is to <entity id="H93-1060.61">provide</entity> a <entity id="H93-1060.62">lexicon</entity> available without <entity id="H93-1060.63">license</entity> <entity id="H93-1060.64">constraint</entity> to all Consortium members. Finally, our <entity id="H93-1060.65">goal</entity> is to <entity id="H93-1060.66">provide</entity> an initial <entity id="H93-1060.67">lexicon</entity> relatively quickly 
 within about a year, funding permitting. This implies a certain <entity id="H93-1060.68">flexibility</entity>, where some of the <entity id="H93-1060.69">features</entity> will probably be changed and refined as the <entity id="H93-1060.70">coding</entity> is taking place. "
</abstract>


</text>

<text id="A97-1008"><title>
An <entity id="A97-1008.1">Evaluation</entity> Of <entity id="A97-1008.2">Strategies</entity> For Selective <entity id="A97-1008.3">Utterance</entity> <entity id="A97-1008.4">Verification</entity> For Spoken <entity id="A97-1008.5">Natural Language</entity> <entity id="A97-1008.6">Dialog</entity></title><abstract>
As with human-human <entity id="A97-1008.7">interaction</entity>, spoken <entity id="A97-1008.8">human-computer</entity> <entity id="A97-1008.9">dialog</entity> will contain <entity id="A97-1008.10">situations</entity> where there is miscommunication. In <entity id="A97-1008.11">experimental</entity> trials consisting of eight different <entity id="A97-1008.12">users</entity>, 141 <entity id="A97-1008.13">problem-solving</entity> <entity id="A97-1008.14">dialogs</entity>, and 2840 <entity id="A97-1008.15">user</entity> <entity id="A97-1008.16">utterances</entity>, the Circuit Fix-It Shop <entity id="A97-1008.17">natural language</entity> <entity id="A97-1008.18">dialog system</entity> misinterpreted 18.5% of <entity id="A97-1008.19">user</entity> <entity id="A97-1008.20">utterances</entity>. These miscommunications created various <entity id="A97-1008.21">problems</entity> for the <entity id="A97-1008.22">dialog</entity> <entity id="A97-1008.23">interaction</entity>, ranging from repetitive <entity id="A97-1008.24">dialog</entity> to experimenter intervention to occasional failure of the <entity id="A97-1008.25">dialog</entity>. One <entity id="A97-1008.26">natural</entity> <entity id="A97-1008.27">strategy</entity> for reducing the <entity id="A97-1008.28">impact</entity> of miscommunication is selective <entity id="A97-1008.29">verification</entity> of the <entity id="A97-1008.30">user</entity>'s <entity id="A97-1008.31">utterances</entity>. This <entity id="A97-1008.32">paper</entity> <entity id="A97-1008.33">reports</entity> on both <entity id="A97-1008.34">context-independent</entity> and <entity id="A97-1008.35">context-dependent</entity> <entity id="A97-1008.36">strategies</entity> for <entity id="A97-1008.37">utterance</entity> <entity id="A97-1008.38">verification</entity> that show that the use of <entity id="A97-1008.39">dialog</entity> <entity id="A97-1008.40">context</entity> is crucial for intelligent <entity id="A97-1008.41">selection</entity> of which <entity id="A97-1008.42">utterances</entity> to verify.
</abstract>


</text>

<text id="W97-1206"><title><entity id="W97-1206.1">Computing</entity> Prosodic Properties In A <entity id="W97-1206.2">Data-</entity>To-<entity id="W97-1206.3">Speech</entity> <entity id="W97-1206.4">System</entity></title><abstract>
We <entity id="W97-1206.5">propose</entity> a set of <entity id="W97-1206.6">rules</entity> for the <entity id="W97-1206.7">computation</entity> of <entity id="W97-1206.8">prosody</entity> which are <entity id="W97-1206.9">implemented</entity> in an existing generic <entity id="W97-1206.10">Data-to-</entity><entity id="W97-1206.11">Speech</entity> <entity id="W97-1206.12">system</entity>. The <entity id="W97-1206.13">rules</entity> make crucial use of both <entity id="W97-1206.14">sentence-internal</entity> and <entity id="W97-1206.15">sentence-external</entity> <entity id="W97-1206.16">semantic</entity> and <entity id="W97-1206.17">syntactic information</entity> <entity id="W97-1206.18">provided</entity> by the <entity id="W97-1206.19">system</entity>. In a <entity id="W97-1206.20">Text-to-</entity><entity id="W97-1206.21">Speech</entity> <entity id="W97-1206.22">system</entity>, this <entity id="W97-1206.23">information</entity> would have to be obtained through <entity id="W97-1206.24">text analysis</entity>, but in <entity id="W97-1206.25">Data-to-</entity><entity id="W97-1206.26">Speech</entity> it is readily available, and its reliable and detailed character makes it possible to <entity id="W97-1206.27">compute</entity> the prosodie <entity id="W97-1206.28">properties</entity> of <entity id="W97-1206.29">generated</entity> <entity id="W97-1206.30">sentences</entity> in a sophisticated way. This in turn allows for a close <entity id="W97-1206.31">control</entity> of prosodie <entity id="W97-1206.32">realization</entity>, <entity id="W97-1206.33">resulting</entity> in <entity id="W97-1206.34">natural-sounding</entity> <entity id="W97-1206.35">intonation</entity>.
</abstract>


</text>

<text id="W99-0305"><title>
Standardisation <entity id="W99-0305.1">Efforts</entity> On The <entity id="W99-0305.2">Level</entity> Of <entity id="W99-0305.3">Dialogue Act</entity> In The <entity id="W99-0305.4">MATE</entity> <entity id="W99-0305.5">Project</entity></title><abstract>
This <entity id="W99-0305.6">paper</entity> describes the state of the art of <entity id="W99-0305.7">coding</entity> <entity id="W99-0305.8">schemes</entity> for <entity id="W99-0305.9">dialogue acts</entity> and the <entity id="W99-0305.10">efforts</entity> to establish a <entity id="W99-0305.11">standard</entity> in this <entity id="W99-0305.12">field</entity>. We present a <entity id="W99-0305.13">review</entity> and <entity id="W99-0305.14">comparison</entity> of currently available <entity id="W99-0305.15">schemes</entity> and <entity id="W99-0305.16">outline</entity> the <entity id="W99-0305.17">comparison</entity> <entity id="W99-0305.18">problems</entity> we had <entity id="W99-0305.19">due</entity> to <entity id="W99-0305.20">domain</entity>, <entity id="W99-0305.21">task</entity>, and <entity id="W99-0305.22">language</entity> <entity id="W99-0305.23">dependencies</entity> of <entity id="W99-0305.24">schemes</entity>. We discuss <entity id="W99-0305.25">solution</entity> <entity id="W99-0305.26">strategies</entity> which have in mind the reusability of <entity id="W99-0305.27">corpora</entity>. Reusability is a crucial point because production and annotation of <entity id="W99-0305.28">corpora</entity> is very <entity id="W99-0305.29">time</entity> and <entity id="W99-0305.30">cost</entity> consuming but the <entity id="W99-0305.31">current</entity> broad <entity id="W99-0305.32">variety</entity> of <entity id="W99-0305.33">schemes</entity> makes reusability of annotated <entity id="W99-0305.34">corpora</entity> very hard. The work of this <entity id="W99-0305.35">paper</entity> takes place in the <entity id="W99-0305.36">framework</entity> of the European Union funded <entity id="W99-0305.37">MATE</entity> <entity id="W99-0305.38">project</entity>. <entity id="W99-0305.39">MATE</entity> aims to <entity id="W99-0305.40">develop</entity> general methodological <entity id="W99-0305.41">guidelines</entity> for the <entity id="W99-0305.42">creation</entity>, annotation, <entity id="W99-0305.43">retrieval</entity> and <entity id="W99-0305.44">analysis</entity> of annotated <entity id="W99-0305.45">corpora</entity>.
</abstract>


</text>

<text id="W00-1002"><title>
ADAM - An <entity id="W00-1002.1">Architecture</entity> For XML-Based <entity id="W00-1002.2">Dialogue</entity> Annotation On Multiple Levels
</title><abstract>
In this <entity id="W00-1002.3">paper</entity> annotation modularity and use of annotation meta-schemes are identified as <entity id="W00-1002.4">basic</entity> <entity id="W00-1002.5">requirements</entity> for achieving actual <entity id="W00-1002.6">corpora</entity> reusability. We discuss these <entity id="W00-1002.7">concepts</entity> and the way they are <entity id="W00-1002.8">implemented</entity> in the architectural <entity id="W00-1002.9">framework</entity> of the ADAM <entity id="W00-1002.10">corpus</entity>, which is a <entity id="W00-1002.11">corpus</entity> of 450 Italian spontaneous <entity id="W00-1002.12">dialogues</entity>. The <entity id="W00-1002.13">design</entity> of ADAM <entity id="W00-1002.14">architecture</entity> is compatible with as many <entity id="W00-1002.15">practices</entity> of <entity id="W00-1002.16">dialogue</entity> annotation as possible, as well as <entity id="W00-1002.17">approaches</entity> to annotation at different <entity id="W00-1002.18">levels</entity>.
</abstract>


</text>

<text id="W00-1213"><title>
Annotating <entity id="W00-1213.1">Information</entity> <entity id="W00-1213.2">Structures</entity> In <entity id="W00-1213.3">Chinese</entity> <entity id="W00-1213.4">Texts</entity> Using HowNet
</title><abstract>
This <entity id="W00-1213.5">paper</entity> <entity id="W00-1213.6">reported</entity> our work on annotating <entity id="W00-1213.7">Chinese</entity> <entity id="W00-1213.8">texts</entity> with <entity id="W00-1213.9">information structures</entity> derived from HowNet. An <entity id="W00-1213.10">information structure</entity> consists of two <entity id="W00-1213.11">components</entity>: HowNet <entity id="W00-1213.12">definitions</entity> and <entity id="W00-1213.13">dependency relations</entity>. It is the <entity id="W00-1213.14">unit</entity> of <entity id="W00-1213.15">representation</entity> of the meaning of <entity id="W00-1213.16">texts</entity>. This work is <entity id="W00-1213.17">part</entity> of a multi-sentential <entity id="W00-1213.18">approach</entity> to <entity id="W00-1213.19">Chinese</entity> <entity id="W00-1213.20">text</entity> <entity id="W00-1213.21">understanding</entity>. An <entity id="W00-1213.22">overview</entity> of <PERSON>HowNet</PERSON> and <entity id="W00-1213.23">information structure</entity> are described in this <entity id="W00-1213.24">paper</entity>.
</abstract>


</text>

<text id="W02-0221"><title><entity id="W02-0221.1">Training</entity> A <entity id="W02-0221.2">Dialogue Act</entity> Tagger For Human-Human And Human-<entity id="W02-0221.3">Computer</entity> Travel Dialogues
</title><abstract>
While <entity id="W02-0221.4">dialogue acts</entity> <entity id="W02-0221.5">provide</entity> a useful <entity id="W02-0221.6">schema</entity> for characterizing <entity id="W02-0221.7">dialogue</entity> <entity id="W02-0221.8">behaviors</entity> in <entity id="W02-0221.9">human-computer</entity> and human-human <entity id="W02-0221.10">dialogues</entity>, their <entity id="W02-0221.11">utility</entity> is <entity id="W02-0221.12">limited</entity> by the huge <entity id="W02-0221.13">effort</entity> involved in <entity id="W02-0221.14">hand-labelling</entity> <entity id="W02-0221.15">dialogues</entity> with a <entity id="W02-0221.16">dialogue act</entity> labelling <entity id="W02-0221.17">scheme</entity>. In this work, we examine whether it is possible to fully automate the <entity id="W02-0221.18">tagging</entity> <entity id="W02-0221.19">task</entity> with the <entity id="W02-0221.20">goal</entity> of enabling rapid <entity id="W02-0221.21">creation</entity> of <entity id="W02-0221.22">corpora</entity> for <entity id="W02-0221.23">evaluating</entity> spoken <entity id="W02-0221.24">dialogue systems</entity> and comparing them to human-human <entity id="W02-0221.25">dialogues</entity>. We <entity id="W02-0221.26">report</entity> <entity id="W02-0221.27">results</entity> for <entity id="W02-0221.28">training</entity> and <entity id="W02-0221.29">testing</entity> an <entity id="W02-0221.30">automatic</entity> <entity id="W02-0221.31">classifier</entity> to label the <entity id="W02-0221.32">information</entity> provider's <entity id="W02-0221.33">utterances</entity> in spoken <entity id="W02-0221.34">human-computer</entity> and human-human <entity id="W02-0221.35">dialogues</entity> with <entity id="W02-0221.36">DATE</entity> (<entity id="W02-0221.37">Dialogue Act</entity> <entity id="W02-0221.38">Tagging</entity> for <entity id="W02-0221.39">Evaluation</entity>) <entity id="W02-0221.40">dialogue act</entity> <entity id="W02-0221.41">tags</entity>. We <entity id="W02-0221.42">train</entity> and <entity id="W02-0221.43">test</entity> the <entity id="W02-0221.44">DATE</entity> tagger on various <entity id="W02-0221.45">combinations</entity> of the DARPA Communicator June-2000 and October-2001 <entity id="W02-0221.46">human-computer</entity> <entity id="W02-0221.47">corpora</entity>, and the CMU human-human <entity id="W02-0221.48">corpus</entity> in the travel planning <entity id="W02-0221.49">domain</entity>. Our <entity id="W02-0221.50">results</entity> show that we can achieve high <entity id="W02-0221.51">accuracies</entity> on the humancomputer data, and surprisingly, that the <entity id="W02-0221.52">human-computer</entity><entity id="W02-0221.53">data</entity> <entity id="W02-0221.54">improves</entity> <entity id="W02-0221.55">accuracy</entity> on the human-human data, when only small <entity id="W02-0221.56">amounts</entity> of human-human <entity id="W02-0221.57">training</entity><entity id="W02-0221.58">data</entity> are available.
</abstract>


</text>

<text id="W02-1504"><title><entity id="W02-1504.1">Machine Translation</entity> As A Testbed For Multilingual <entity id="W02-1504.2">Analysis</entity></title><abstract>
We <entity id="W02-1504.3">propose</entity> that <entity id="W02-1504.4">machine translation</entity> (MT) is a useful <entity id="W02-1504.5">application</entity> for <entity id="W02-1504.6">evaluating</entity> and deriving the <entity id="W02-1504.7">development</entity> of NL <entity id="W02-1504.8">components</entity>, especially in a <entity id="W02-1504.9">wide-coverage</entity> <entity id="W02-1504.10">analysis</entity> <entity id="W02-1504.11">system</entity>. Given the <entity id="W02-1504.12">architecture</entity> of our <entity id="W02-1504.13">MT system</entity>, which is a <entity id="W02-1504.14">transfer</entity> <entity id="W02-1504.15">system</entity> <entity id="W02-1504.16">based</entity> on linguistic <entity id="W02-1504.17">modules</entity>, correct <entity id="W02-1504.18">analysis</entity> is expected to be a prerequisite for correct <entity id="W02-1504.19">translation</entity>, suggesting a <entity id="W02-1504.20">correlation</entity> between the two, given relatively mature <entity id="W02-1504.21">transfer</entity> and <entity id="W02-1504.22">generation</entity> <entity id="W02-1504.23">components</entity>. We show through <entity id="W02-1504.24">error analysis</entity> that there is indeed a strong <entity id="W02-1504.25">correlation</entity> between the <entity id="W02-1504.26">quality</entity> of the <entity id="W02-1504.27">translated</entity> <entity id="W02-1504.28">output</entity> and the subjectively determined goodness of the <entity id="W02-1504.29">analysis</entity>. We use this <entity id="W02-1504.30">correlation</entity> as a guide for <entity id="W02-1504.31">development</entity> of a coordinated parallel <entity id="W02-1504.32">analysis</entity> <entity id="W02-1504.33">effort</entity> in 7 <entity id="W02-1504.34">languages</entity>.
</abstract>


</text>

<text id="W03-0421"><title>
A <entity id="W03-0421.1">Simple</entity> <entity id="W03-0421.2">Named</entity> <entity id="W03-0421.3">Entity</entity> <entity id="W03-0421.4">Extractor</entity> Using AdaBoost
</title><abstract>
This <entity id="W03-0421.5">paper</entity> presents a <entity id="W03-0421.6">Named</entity> <entity id="W03-0421.7">Entity</entity> <entity id="W03-0421.8">Extraction</entity> (NEE) <entity id="W03-0421.9">system</entity> for the CoNLL-2003 shared <entity id="W03-0421.10">task</entity> <entity id="W03-0421.11">competition</entity>. As in the past year edition ( <BIBLIO>Carreras et al., 2002a</BIBLIO> ), we have <entity id="W03-0421.12">approached</entity> the <entity id="W03-0421.13">task</entity> by treating the two <entity id="W03-0421.14">main</entity> sub-tasks of the <entity id="W03-0421.15">problem</entity>, <entity id="W03-0421.16">recognition</entity> (NER) and <entity id="W03-0421.17">classification</entity> (NEC), sequentially and independently with separate <entity id="W03-0421.18">modules</entity>. Both <entity id="W03-0421.19">modules</entity> are <entity id="W03-0421.20">machine</entity> learning <entity id="W03-0421.21">based</entity> <entity id="W03-0421.22">systems</entity>, which make use of binary and multiclass AdaBoost <entity id="W03-0421.23">classifiers</entity>. <entity id="W03-0421.24">Named</entity> <entity id="W03-0421.25">Entity</entity> <entity id="W03-0421.26">recognition</entity> is <entity id="W03-0421.27">performed</entity> as a greedy <entity id="W03-0421.28">sequence</entity> <entity id="W03-0421.29">tagging</entity> <entity id="W03-0421.30">procedure</entity> under the well-known BIO labelling <entity id="W03-0421.31">scheme</entity>. This <entity id="W03-0421.32">tagging</entity> <entity id="W03-0421.33">process</entity> makes use of three binary <entity id="W03-0421.34">classifiers</entity> <entity id="W03-0421.35">trained</entity> to be <entity id="W03-0421.36">experts</entity></abstract>


</text>

<text id="W03-0802"><title>
WHAT: An XSLT-Based <entity id="W03-0802.1">Infrastructure</entity> For The <entity id="W03-0802.2">Integration</entity> Of <entity id="W03-0802.3">Natural Language Processing</entity> Components
</title><abstract>
The idea of the Whiteboard <entity id="W03-0802.4">project</entity> is to integrate deep and shallow <entity id="W03-0802.5">natural language processing</entity> <entity id="W03-0802.6">components</entity> in <entity id="W03-0802.7">order</entity> to <entity id="W03-0802.8">benefit</entity> from their synergy. The <entity id="W03-0802.9">project</entity> came up with the first fully integrated hybrid <entity id="W03-0802.10">system</entity> consisting of a fast HPSG <entity id="W03-0802.11">parser</entity> that utilizes tokenization, PoS, <entity id="W03-0802.12">morphology</entity>, <entity id="W03-0802.13">lexical</entity>, <entity id="W03-0802.14">named</entity> <entity id="W03-0802.15">entity</entity>, <entity id="W03-0802.16">phrase</entity> <entity id="W03-0802.17">chunk</entity> and (for German) topological <entity id="W03-0802.18">sentence</entity> <entity id="W03-0802.19">field</entity> <entity id="W03-0802.20">analyses</entity> from shallow <entity id="W03-0802.21">components</entity>. This <entity id="W03-0802.22">integration</entity> <entity id="W03-0802.23">increases</entity> <entity id="W03-0802.24">robustness</entity>, directs the <entity id="W03-0802.25">search space</entity> and hence reduces <entity id="W03-0802.26">processing</entity> <entity id="W03-0802.27">time</entity> of the deep <entity id="W03-0802.28">parser</entity>. In this <entity id="W03-0802.29">paper</entity>, we <entity id="W03-0802.30">focus</entity> on one of the central <entity id="W03-0802.31">integration</entity> facilities, the XSLT-based Whiteboard Annotation Transformer (WHAT), <entity id="W03-0802.32">report</entity> on the <entity id="W03-0802.33">benefits</entity> of XSLT-based NLP <entity id="W03-0802.34">component</entity> <entity id="W03-0802.35">integration</entity>, and present <entity id="W03-0802.36">examples</entity> of XSL <entity id="W03-0802.37">transformation</entity> of shallow and deep annotations used in the integrated <entity id="W03-0802.38">architecture</entity>. The <entity id="W03-0802.39">infrastructure</entity> is open, portable and well suited for, but not restricted to the <entity id="W03-0802.40">development</entity> of hybrid NLP <entity id="W03-0802.41">architectures</entity> as well as <entity id="W03-0802.42">NLP applications</entity>.
</abstract>


</text>

<text id="W99-0907"><title>
Detecting Sub-<entity id="W99-0907.1">Topic</entity> <entity id="W99-0907.2">Correspondence</entity> Through Bipartite <entity id="W99-0907.3">Term</entity> Clustering
</title><abstract>
This <entity id="W99-0907.4">paper</entity> addresses a novel <entity id="W99-0907.5">task</entity> of detecting <entity id="W99-0907.6">sub-topic</entity> <entity id="W99-0907.7">correspondence</entity> in a <entity id="W99-0907.8">pair</entity> of <entity id="W99-0907.9">text</entity> <entity id="W99-0907.10">fragments</entity>, enhancing <entity id="W99-0907.11">common</entity> <entity id="W99-0907.12">notions</entity> of <entity id="W99-0907.13">text</entity> <entity id="W99-0907.14">similarity</entity>. This <entity id="W99-0907.15">task</entity> is addressed by coupling corresponding <entity id="W99-0907.16">term</entity> subsets through bipartite <entity id="W99-0907.17">clustering</entity>. The <entity id="W99-0907.18">paper</entity> presents a <entity id="W99-0907.19">cost-based</entity> <entity id="W99-0907.20">clustering</entity> <entity id="W99-0907.21">scheme</entity> and compares it with a bipartite <entity id="W99-0907.22">version</entity> of the <entity id="W99-0907.23">single-link</entity> <entity id="W99-0907.24">method</entity>, <entity id="W99-0907.25">providing</entity> illustrating <entity id="W99-0907.26">results</entity>.
</abstract>


</text>

<text id="W08-0327"><title>
Can we Relearn an RBMT <entity id="W08-0327.1">System</entity>?
</title><abstract>
This <entity id="W08-0327.2">paper</entity> describes SYSTRAN <entity id="W08-0327.3">submissions</entity> for the shared <entity id="W08-0327.4">task</entity> of the third <entity id="W08-0327.5">Workshop</entity> on <entity id="W08-0327.6">Statistical Machine Translation</entity> at ACL. Our <entity id="W08-0327.7">main</entity> <entity id="W08-0327.8">contribution</entity> consists in a French-<entity id="W08-0327.9">English</entity> <entity id="W08-0327.10">statistical model</entity> <entity id="W08-0327.11">trained</entity> without the use of any human-translated <entity id="W08-0327.12">parallel corpus</entity>. In <entity id="W08-0327.13">substitution</entity>, we <entity id="W08-0327.14">translated</entity> a monolingual <entity id="W08-0327.15">corpus</entity> with SYSTRAN <entity id="W08-0327.16">rule-based</entity> <entity id="W08-0327.17">translation</entity> <entity id="W08-0327.18">engine</entity> to produce the <entity id="W08-0327.19">parallel corpus</entity>. The <entity id="W08-0327.20">results</entity> are <entity id="W08-0327.21">provided</entity> herein, along with a measure of <entity id="W08-0327.22">error analysis</entity>.
</abstract>


</text>

<text id="J95-1004"><title>
An <entity id="J95-1004.1">Automatic</entity> <entity id="J95-1004.2">Procedure</entity> For <entity id="J95-1004.3">Topic-</entity><entity id="J95-1004.4">Focus</entity> <entity id="J95-1004.5">Identification</entity></title><abstract>
The dichotomy of <entity id="J95-1004.6">topic</entity> and <entity id="J95-1004.7">focus</entity>, <entity id="J95-1004.8">based</entity>, in the Praguean Functional Generative <entity id="J95-1004.9">Description</entity>, on the <entity id="J95-1004.10">scale</entity> of communicative dynamism, is relevant not only for a possible placement of the <entity id="J95-1004.11">sentence</entity> in a <entity id="J95-1004.12">context</entity>, but also for its <entity id="J95-1004.13">semantic interpretation</entity>. An <entity id="J95-1004.14">automatic</entity> <entity id="J95-1004.15">identification</entity> of <entity id="J95-1004.16">topic</entity> and <entity id="J95-1004.17">focus</entity> may use the <entity id="J95-1004.18">input</entity> <entity id="J95-1004.19">information</entity> on <entity id="J95-1004.20">word</entity> <entity id="J95-1004.21">order</entity>, on the systemic <entity id="J95-1004.22">ordering</entity> of <entity id="J95-1004.23">kinds</entity> of complementations (reflected by the underlying <entity id="J95-1004.24">order</entity> of the <entity id="J95-1004.25">items</entity> <entity id="J95-1004.26">included</entity> in the <entity id="J95-1004.27">focus</entity>), on definiteness, and on <entity id="J95-1004.28">lexical</entity> <entity id="J95-1004.29">semantic properties</entity> of <entity id="J95-1004.30">words</entity>. An <entity id="J95-1004.31">algorithm</entity> for the <entity id="J95-1004.32">analysis</entity> of <entity id="J95-1004.33">English</entity> <entity id="J95-1004.34">sentences</entity> has been <entity id="J95-1004.35">implemented</entity> and is discussed and illustrated on several <entity id="J95-1004.36">examples</entity>.
</abstract>


</text>

<text id="J96-3003"><title>
Efficient Multilingual <entity id="J96-3003.1">Phoneme-</entity>To-Grapheme <entity id="J96-3003.2">Conversion</entity> <entity id="J96-3003.3">Based</entity> On HMM
</title>
<abstract><entity id="J96-3003.4">Grapheme-to-phoneme</entity> <entity id="J96-3003.5">conversion</entity> (GTPC) has been achieved in most European <entity id="J96-3003.6">languages</entity> by <entity id="J96-3003.7">dictionary</entity> look-up or using <entity id="J96-3003.8">rules</entity>. The <entity id="J96-3003.9">application</entity> of these <entity id="J96-3003.10">methods</entity>, however, in the reverse <entity id="J96-3003.11">process</entity>, (i.e., in <entity id="J96-3003.12">phoneme-to-grapheme</entity> <entity id="J96-3003.13">conversion</entity> [PTGC]) creates serious <entity id="J96-3003.14">problems</entity>, especially in inflectionally rich <entity id="J96-3003.15">languages</entity>. In this <entity id="J96-3003.16">paper</entity> the PTGC <entity id="J96-3003.17">problem</entity> is <entity id="J96-3003.18">approached</entity> from a completely different <entity id="J96-3003.19">point of view</entity>. Instead of <entity id="J96-3003.20">rules</entity> or a <entity id="J96-3003.21">dictionary</entity>, the <entity id="J96-3003.22">statistics</entity> of <entity id="J96-3003.23">language</entity> connecting <entity id="J96-3003.24">pronunciation</entity> to <entity id="J96-3003.25">spelling</entity> are exploited. The <entity id="J96-3003.26">novelty</entity> lies in <entity id="J96-3003.27">modeling</entity> the <entity id="J96-3003.28">natural language</entity> intraword <entity id="J96-3003.29">features</entity> using the <entity id="J96-3003.30">theory</entity> of hidden <entity id="J96-3003.31">Markov models</entity> (HMM) and <entity id="J96-3003.32">performing</entity> the <entity id="J96-3003.33">conversion</entity> using the <PERSON>Viterbi</PERSON> <entity id="J96-3003.34">algorithm</entity>. The PTGC <entity id="J96-3003.35">system</entity> has been established and <entity id="J96-3003.36">tested</entity> on various multilingual <entity id="J96-3003.37">corpora</entity>. Initially, the <entity id="J96-3003.38">first-order</entity> HMM and the <entity id="J96-3003.39">common</entity> <PERSON>Viterbi</PERSON> <entity id="J96-3003.40">algorithm</entity> were used to obtain a single <entity id="J96-3003.41">transcription</entity> for each <entity id="J96-3003.42">word</entity>. Afterwards, the <entity id="J96-3003.43">second-order</entity> HMM and the N-best <entity id="J96-3003.44">algorithm</entity> <entity id="J96-3003.45">adapted</entity> to PTGC were <entity id="J96-3003.46">implemented</entity> to <entity id="J96-3003.47">provide</entity> one or more <entity id="J96-3003.48">transcriptions</entity> for each <entity id="J96-3003.49">word</entity> <entity id="J96-3003.50">input</entity> (homophones). This <entity id="J96-3003.51">system</entity> gave an average score of more than 99% correctly transcribed <entity id="J96-3003.52">words</entity> (overall <entity id="J96-3003.53">success</entity> in the first four <entity id="J96-3003.54">candidates</entity>) for most of the seven <entity id="J96-3003.55">languages</entity> it was <entity id="J96-3003.56">tested</entity> on (Dutch, <entity id="J96-3003.57">English</entity>, French, German, <entity id="J96-3003.58">Greek</entity>, Italian, and Spanish). The <entity id="J96-3003.59">system</entity> can be <entity id="J96-3003.60">adapted</entity> to almost any <entity id="J96-3003.61">language</entity> with little <entity id="J96-3003.62">effort</entity> and can be <entity id="J96-3003.63">implemented</entity> in hardware to serve in <entity id="J96-3003.64">real-time</entity> <entity id="J96-3003.65">speech recognition systems</entity>.
</abstract>


</text>

<text id="P80-1007"><title>
Should <entity id="P80-1007.1">Computers</entity> Write <entity id="P80-1007.2">Spoken Language</entity>?
</title><abstract></abstract>


</text>

<text id="P98-2171"><title>
From <entity id="P98-2171.1">Information Structure</entity> to <entity id="P98-2171.2">Intonation</entity>: A Phonological <entity id="P98-2171.3">Interface</entity> for <entity id="P98-2171.4">Concept-to-</entity><entity id="P98-2171.5">Speech</entity></title><abstract>
The <entity id="P98-2171.6">paper</entity> describes an <entity id="P98-2171.7">interface</entity> between <entity id="P98-2171.8">generator</entity> and synthesizer of the German <entity id="P98-2171.9">language</entity> <entity id="P98-2171.10">concept-to-speech</entity> <entity id="P98-2171.11">system</entity> VieCtoS. It discusses <entity id="P98-2171.12">phenomena</entity> in German <entity id="P98-2171.13">intonation</entity> that depend on the <entity id="P98-2171.14">interaction</entity> between grammatical <entity id="P98-2171.15">dependencies</entity> (<entity id="P98-2171.16">projection</entity> of <entity id="P98-2171.17">information structure</entity> into <entity id="P98-2171.18">syntax</entity>) and prosodie <entity id="P98-2171.19">context</entity> (<entity id="P98-2171.20">performance-related</entity> <entity id="P98-2171.21">modifications</entity> to <entity id="P98-2171.22">intonation</entity> <entity id="P98-2171.23">patterns</entity>). Phonological <entity id="P98-2171.24">processing</entity> in our <entity id="P98-2171.25">system</entity> comprises segmental as well as suprasegmental <entity id="P98-2171.26">dimensions</entity> such as syllabification, <entity id="P98-2171.27">modification</entity> of <entity id="P98-2171.28">word</entity> stress positions, and a symbolic encoding of <entity id="P98-2171.29">intonation</entity>. Phonological <entity id="P98-2171.30">phenomena</entity> often touch upon more than one of these <entity id="P98-2171.31">dimensions</entity>, so that mutual accessibility of the<entity id="P98-2171.32">data</entity> <entity id="P98-2171.33">structures</entity> on each <entity id="P98-2171.34">dimension</entity> had to be ensured. We present a linear <entity id="P98-2171.35">representation</entity> of the multidimensional phonological<entity id="P98-2171.36">data</entity> <entity id="P98-2171.37">based</entity> on a straightforward linearization <entity id="P98-2171.38">convention</entity>, which suffices to bring this conceptually multilinear<entity id="P98-2171.39">data</entity> set under the <entity id="P98-2171.40">scope</entity> of the well-known <entity id="P98-2171.41">processing</entity> <entity id="P98-2171.42">techniques</entity> for <entity id="P98-2171.43">two-level</entity> <entity id="P98-2171.44">morphology</entity>.
</abstract>


</text>

<text id="P98-2175"><title>
An Intelligent Multi-<entity id="P98-2175.1">Dictionary</entity> <entity id="P98-2175.2">Environment</entity></title><abstract>
An open, extendible <entity id="P98-2175.3">multi-dictionary</entity> <entity id="P98-2175.4">system</entity> is introduced in the <entity id="P98-2175.5">paper</entity>. It <entity id="P98-2175.6">supports</entity> the <entity id="P98-2175.7">translator</entity> in <entity id="P98-2175.8">accessing</entity> adequate <entity id="P98-2175.9">entries</entity> of various bi- and monolingual <entity id="P98-2175.10">dictionaries</entity> and <entity id="P98-2175.11">translation</entity> <entity id="P98-2175.12">examples</entity> from <entity id="P98-2175.13">parallel corpora</entity>. Simultaneously an unlimited <entity id="P98-2175.14">number</entity> of <entity id="P98-2175.15">dictionaries</entity> can be held open, thus by a single interrogation <entity id="P98-2175.16">step</entity>, all the <entity id="P98-2175.17">dictionaries</entity> (<entity id="P98-2175.18">translations</entity>, <entity id="P98-2175.19">explanations</entity>, <entity id="P98-2175.20">synonyms</entity>, etc.) can be <entity id="P98-2175.21">surveyed</entity>. The <entity id="P98-2175.22">implemented</entity> <entity id="P98-2175.23">system</entity> (<entity id="P98-2175.24">called</entity> MoBiDic) knows morphological <entity id="P98-2175.25">rules</entity> of the <entity id="P98-2175.26">dictionaries</entity>' <entity id="P98-2175.27">languages</entity>. Thus, never the actual (inflected) <entity id="P98-2175.28">words</entity>, but always their <entity id="P98-2175.29">lemmas</entity> - that is, the right <entity id="P98-2175.30">dictionary</entity> <entity id="P98-2175.31">entries</entity> - are looked up. MoBiDic has an open, multimedial <entity id="P98-2175.32">architecture</entity>, thus it is suitable for handling not only textual, but speaking or picture <entity id="P98-2175.33">dictionaries</entity>, as well. The same <entity id="P98-2175.34">system</entity> is also able to find <entity id="P98-2175.35">words</entity> and <entity id="P98-2175.36">expressions</entity> in <entity id="P98-2175.37">corpora</entity>, dynamically <entity id="P98-2175.38">providing</entity> the <entity id="P98-2175.39">translators</entity> with <entity id="P98-2175.40">examples</entity> from their earlier <entity id="P98-2175.41">translations</entity> or other <entity id="P98-2175.42">translators</entity>' works. MoBiDic has been <entity id="P98-2175.43">designed</entity> for <entity id="P98-2175.44">translator</entity> workgroups, where the <entity id="P98-2175.45">translators</entity>' own glossaries (built also with the <entity id="P98-2175.46">help</entity> of the <entity id="P98-2175.47">system</entity>) may also be disseminated among the members of the group, with different <entity id="P98-2175.48">access</entity> rights, if needed. The <entity id="P98-2175.49">system</entity> has a TCP/IP-based <entity id="P98-2175.50">client-server</entity> <entity id="P98-2175.51">implementation</entity> for various <entity id="P98-2175.52">platforms</entity> and available with a gradually <entity id="P98-2175.53">increasing</entity> <entity id="P98-2175.54">number</entity> of <entity id="P98-2175.55">dictionaries</entity> for numerous <entity id="P98-2175.56">language pairs</entity>.
</abstract>


</text>

<text id="I08-1001"><title>
A Lemmatization <entity id="I08-1001.1">Method</entity> for Modern Mongolian and its <entity id="I08-1001.2">Application</entity> to <entity id="I08-1001.3">Information Retrieval</entity></title><abstract>
In Modern Mongolian, a <entity id="I08-1001.4">content word</entity> can be inflected when concatenated with <entity id="I08-1001.5">suffixes</entity>. <entity id="I08-1001.6">Identifying</entity> the original <entity id="I08-1001.7">forms</entity> of <entity id="I08-1001.8">content words</entity> is crucial for <entity id="I08-1001.9">natural language processing</entity> and <entity id="I08-1001.10">information retrieval</entity>. We <entity id="I08-1001.11">propose</entity> a lemmatization <entity id="I08-1001.12">method</entity> for Modern Mongolian and <entity id="I08-1001.13">apply</entity> our <entity id="I08-1001.14">method</entity> to <entity id="I08-1001.15">indexing</entity> for <entity id="I08-1001.16">information retrieval</entity>. We use technical <entity id="I08-1001.17">abstracts</entity> to show the <entity id="I08-1001.18">effectiveness</entity> of our <entity id="I08-1001.19">method</entity> experimentally.
</abstract>


</text>

<text id="W04-2003"><title>
A <entity id="W04-2003.1">Robust</entity> And Hybrid Deep-<entity id="W04-2003.2">Linguistic Theory</entity> <entity id="W04-2003.3">Applied</entity> To Large-<entity id="W04-2003.4">Scale</entity> <entity id="W04-2003.5">Parsing</entity></title><abstract>
Modern <entity id="W04-2003.6">statistical</entity> <entity id="W04-2003.7">parsers</entity> are <entity id="W04-2003.8">robust</entity> and quite fast, but their <entity id="W04-2003.9">output</entity> is relatively shallow when compared to formal grammar <entity id="W04-2003.10">parsers</entity>. We suggest to extend <entity id="W04-2003.11">statistical</entity> <entity id="W04-2003.12">approaches</entity> to a more <entity id="W04-2003.13">deep-linguistic analysis</entity> while at the same <entity id="W04-2003.14">time</entity> keeping the <entity id="W04-2003.15">speed</entity> and low <entity id="W04-2003.16">complexity</entity> of a <entity id="W04-2003.17">statistical</entity> <entity id="W04-2003.18">parser</entity>. The <entity id="W04-2003.19">resulting</entity> <entity id="W04-2003.20">parsing</entity> <entity id="W04-2003.21">architecture</entity> suggested, <entity id="W04-2003.22">implemented</entity> and <entity id="W04-2003.23">evaluated</entity> here is highly robust and hybrid on a number of <entity id="W04-2003.24">levels</entity>, combining <entity id="W04-2003.25">statistical</entity> and <entity id="W04-2003.26">rule-based approaches</entity>, <entity id="W04-2003.27">constituency</entity> and <entity id="W04-2003.28">dependency grammar</entity>, shallow and deep <entity id="W04-2003.29">processing</entity>, full and near-full <entity id="W04-2003.30">parsing</entity>. With its <entity id="W04-2003.31">parsing</entity> <entity id="W04-2003.32">speed</entity> of about 300,000 <entity id="W04-2003.33">words</entity> per hour and state-of-the-art <entity id="W04-2003.34">performance</entity> the <entity id="W04-2003.35">parser</entity> is reliable for a <entity id="W04-2003.36">number</entity> of <entity id="W04-2003.37">large-scale</entity> <entity id="W04-2003.38">applications</entity> discussed in the article.
</abstract>


</text>

<text id="W04-2306"><title>
Semi-<entity id="W04-2306.1">Automatic</entity> <entity id="W04-2306.2">Generation</entity> Of <entity id="W04-2306.3">Dialogue</entity> <entity id="W04-2306.4">Applications</entity> In The GEMINI <entity id="W04-2306.5">Project</entity></title><abstract>
GEMINI (Generic <entity id="W04-2306.6">Environment</entity> for Multilingual Interactive <entity id="W04-2306.7">Natural</entity> Interfaces) is an EC funded <entity id="W04-2306.8">research project</entity>, which has two <entity id="W04-2306.9">main</entity> <entity id="W04-2306.10">objectives</entity>: First, the <entity id="W04-2306.11">development</entity> of a flexible <entity id="W04-2306.12">platform</entity> able to produce <entity id="W04-2306.13">user-friendly</entity> interactive multilingual and multi-modal <entity id="W04-2306.14">dialogue</entity> <entity id="W04-2306.15">interfaces</entity> to <entity id="W04-2306.16">databases</entity> with a <entity id="W04-2306.17">minimum</entity> of human <entity id="W04-2306.18">effort</entity>, and, second, the <entity id="W04-2306.19">demonstration</entity> of the <entity id="W04-2306.20">platform</entity>'s <entity id="W04-2306.21">efficiency</entity> through the <entity id="W04-2306.22">development</entity> of two different <entity id="W04-2306.23">applications</entity> <entity id="W04-2306.24">based</entity> on this <entity id="W04-2306.25">platform</entity>: EG-Banking, a voice-portal for <entity id="W04-2306.26">high-quality</entity> <entity id="W04-2306.27">interactions</entity> for <entity id="W04-2306.28">bank</entity> <entity id="W04-2306.29">customers</entity>, and CitizenCare, an e-government <entity id="W04-2306.30">platform</entity> <entity id="W04-2306.31">framework</entity> for citizen-to-administration <entity id="W04-2306.32">interaction</entity> which are available for spoken and web-based <entity id="W04-2306.33">user</entity> <entity id="W04-2306.34">interaction</entity>.
</abstract>


</text>

<text id="W04-2501"><title><entity id="W04-2501.1">Strategies</entity> For Advanced <entity id="W04-2501.2">Question Answering</entity></title>
<abstract><entity id="W04-2501.3">Progress</entity> in <entity id="W04-2501.4">Question Answering</entity> can be achieved by (1) combining multiple <entity id="W04-2501.5">strategies</entity> that optimally resolve different <entity id="W04-2501.6">question</entity> <entity id="W04-2501.7">classes</entity> of various <entity id="W04-2501.8">degrees</entity> of <entity id="W04-2501.9">complexity</entity>; (2) enhancing the <entity id="W04-2501.10">precision</entity> of <entity id="W04-2501.11">question</entity> <entity id="W04-2501.12">interpretation</entity> and answer <entity id="W04-2501.13">extraction</entity>; and (3) <entity id="W04-2501.14">question</entity> <entity id="W04-2501.15">decomposition</entity> and answer <entity id="W04-2501.16">fusion</entity>. In this <entity id="W04-2501.17">paper</entity> we also present the <entity id="W04-2501.18">impact</entity> of <entity id="W04-2501.19">modeling</entity> the <entity id="W04-2501.20">user</entity> <entity id="W04-2501.21">background</entity> on Q/A and discuss the pragmatics pf <entity id="W04-2501.22">processing</entity> <entity id="W04-2501.23">negation</entity> in Q/A.
</abstract>


</text>

<text id="W05-0617"><title><entity id="W05-0617.1">Morphology</entity> <entity id="W05-0617.2">Induction</entity> From <entity id="W05-0617.3">Term</entity> Clusters
</title><abstract>
We address the <entity id="W05-0617.4">problem</entity> of learning a morphological automaton directly from a monolingual <entity id="W05-0617.5">text</entity> <entity id="W05-0617.6">corpus</entity> without recourse to additional <entity id="W05-0617.7">resources</entity>. Like previous work in this <entity id="W05-0617.8">area</entity>, our <entity id="W05-0617.9">approach</entity> exploits orthographic <entity id="W05-0617.10">regularities</entity> in a <entity id="W05-0617.11">search</entity> for possible morphological segmentation points. Instead of affixes, however, we <entity id="W05-0617.12">search</entity> for affix <entity id="W05-0617.13">transformation</entity> <entity id="W05-0617.14">rules</entity> that express <entity id="W05-0617.15">correspondences</entity> between <entity id="W05-0617.16">term</entity> <entity id="W05-0617.17">clusters</entity> induced from the<entity id="W05-0617.18">data</entity>. This <entity id="W05-0617.19">focuses</entity> the <entity id="W05-0617.20">system</entity> on substrings having <entity id="W05-0617.21">syntactic function</entity>, and <entity id="W05-0617.22">yields</entity> <entity id="W05-0617.23">cluster-to-cluster</entity> <entity id="W05-0617.24">transformation</entity> <entity id="W05-0617.25">rules</entity> which enable the <entity id="W05-0617.26">system</entity> to <entity id="W05-0617.27">process</entity> unknown morphological <entity id="W05-0617.28">forms</entity> of known <entity id="W05-0617.29">words</entity> accurately. A <entity id="W05-0617.30">stem-weighting</entity> <entity id="W05-0617.31">algorithm</entity> <entity id="W05-0617.32">based</entity> on Hubs and Authorities is used to clarify ambiguous segmentation points. We <entity id="W05-0617.33">evaluate</entity> our <entity id="W05-0617.34">approach</entity> using the CELEX <entity id="W05-0617.35">database</entity>.
</abstract>


</text>

<text id="W05-0802"><title><entity id="W05-0802.1">Cross</entity> <entity id="W05-0802.2">Language</entity> <entity id="W05-0802.3">Text Categorization</entity> By Acquiring Multilingual <entity id="W05-0802.4">Domain</entity> <entity id="W05-0802.5">Models</entity> From Comparable <entity id="W05-0802.6">Corpora</entity></title><abstract>
In a multilingual <entity id="W05-0802.7">scenario</entity>, the classical monolingual <entity id="W05-0802.8">text categorization</entity> <entity id="W05-0802.9">problem</entity> can be reformulated as a <entity id="W05-0802.10">cross</entity> <entity id="W05-0802.11">language</entity> TC <entity id="W05-0802.12">English</entity> Italian). <entity id="W05-0802.13">English</entity>), Italian).
</abstract>


</text>

<text id="W05-1514"><title><entity id="W05-1514.1">Chunk</entity> <entity id="W05-1514.2">Parsing</entity> Revisited
</title><abstract><entity id="W05-1514.3">Chunk</entity> <entity id="W05-1514.4">parsing</entity> is conceptually appealing but its <entity id="W05-1514.5">performance</entity> has not been satisfactory for practical use. In this <entity id="W05-1514.6">paper</entity> we show that <entity id="W05-1514.7">chunk</entity> <entity id="W05-1514.8">parsing</entity> can <entity id="W05-1514.9">perform</entity> significantly better than previously <entity id="W05-1514.10">reported</entity> by using a <entity id="W05-1514.11">simple</entity> <entity id="W05-1514.12">sliding-window</entity> <entity id="W05-1514.13">method</entity> and <entity id="W05-1514.14">maximum entropy</entity> <entity id="W05-1514.15">classifiers</entity> for <entity id="W05-1514.16">phrase</entity> <entity id="W05-1514.17">recognition</entity> in each <entity id="W05-1514.18">level</entity> of <entity id="W05-1514.19">chunking</entity>. <entity id="W05-1514.20">Experimental</entity> <entity id="W05-1514.21">results</entity> with the <entity id="W05-1514.22">Penn Treebank</entity> <entity id="W05-1514.23">corpus</entity> show that our <entity id="W05-1514.24">chunk</entity> <entity id="W05-1514.25">parser</entity> can give <entity id="W05-1514.26">high-precision</entity> <entity id="W05-1514.27">parsing</entity> <entity id="W05-1514.28">outputs</entity> with very high <entity id="W05-1514.29">speed</entity> (14 msec/<entity id="W05-1514.30">sentence</entity>). We also present a <entity id="W05-1514.31">parsing</entity> <entity id="W05-1514.32">method</entity> for <entity id="W05-1514.33">searching</entity> the best <entity id="W05-1514.34">parse</entity> by considering the <entity id="W05-1514.35">probabilities</entity> <entity id="W05-1514.36">output</entity> by the <entity id="W05-1514.37">maximum entropy</entity> <entity id="W05-1514.38">classifiers</entity>, and show that the <entity id="W05-1514.39">search</entity> <entity id="W05-1514.40">method</entity> can further <entity id="W05-1514.41">improve</entity> the <entity id="W05-1514.42">parsing</entity> <entity id="W05-1514.43">accuracy</entity>.
</abstract>


</text>

<text id="W06-0205"><title><entity id="W06-0205.1">Automatic</entity> <entity id="W06-0205.2">Knowledge Representation</entity> Using A Graph-<entity id="W06-0205.3">Based</entity> <entity id="W06-0205.4">Algorithm</entity> For <entity id="W06-0205.5">Language-</entity>Independent <entity id="W06-0205.6">Lexical</entity> Chaining
</title><abstract><entity id="W06-0205.7">Lexical Chains</entity> are powerful <entity id="W06-0205.8">representations</entity> of <entity id="W06-0205.9">documents</entity>. In particular, they have successfully been used in the <entity id="W06-0205.10">field</entity> of <entity id="W06-0205.11">Automatic</entity> <entity id="W06-0205.12">Text Summarization</entity>. However, until now, <entity id="W06-0205.13">Lexical</entity> Chaining <entity id="W06-0205.14">algorithms</entity> have only been <entity id="W06-0205.15">proposed</entity> for <entity id="W06-0205.16">English</entity>. In this <entity id="W06-0205.17">paper</entity>, we <entity id="W06-0205.18">propose</entity> a greedy <entity id="W06-0205.19">Language-</entity>Independent <entity id="W06-0205.20">algorithm</entity> that automatically <entity id="W06-0205.21">extracts</entity> <entity id="W06-0205.22">Lexical Chains</entity> from <entity id="W06-0205.23">texts</entity>. For that <entity id="W06-0205.24">purpose</entity>, we build a hierarchical <entity id="W06-0205.25">lexico-semantic knowledge</entity> <entity id="W06-0205.26">base</entity> from a <entity id="W06-0205.27">collection</entity> of <entity id="W06-0205.28">texts</entity> by using the Pole-<entity id="W06-0205.29">Based</entity> Overlapping <entity id="W06-0205.30">Clustering Algorithm</entity>. As a consequence, our <entity id="W06-0205.31">methodology</entity> can be <entity id="W06-0205.32">applied</entity> to any <entity id="W06-0205.33">language</entity> and <entity id="W06-0205.34">proposes</entity> a <entity id="W06-0205.35">solution</entity> to <entity id="W06-0205.36">language-dependent</entity> <entity id="W06-0205.37">Lexical</entity> Chainers.
</abstract>


</text>

<text id="W06-1002"><title>
The <entity id="W06-1002.1">Role</entity> Of <entity id="W06-1002.2">Lexical</entity> Resources In CJK <entity id="W06-1002.3">Natural Language</entity> <entity id="W06-1002.4">Processing</entity></title><abstract>
The <entity id="W06-1002.5">role</entity> of <entity id="W06-1002.6">lexical resources</entity> is often understated in NLP <entity id="W06-1002.7">research</entity>. The <entity id="W06-1002.8">complexity</entity> of <entity id="W06-1002.9">Chinese</entity>, <entity id="W06-1002.10">Japanese</entity> and Korean (CJK) poses special <entity id="W06-1002.11">challenges</entity> to <entity id="W06-1002.12">developers</entity> of NLP <entity id="W06-1002.13">tools</entity>, especially in the <entity id="W06-1002.14">area</entity> of <entity id="W06-1002.15">word segmentation</entity> (WS), <entity id="W06-1002.16">information retrieval</entity> (IR), <entity id="W06-1002.17">named</entity> <entity id="W06-1002.18">entity</entity> <entity id="W06-1002.19">extraction</entity> (NER), and <entity id="W06-1002.20">machine translation</entity> (MT). These <entity id="W06-1002.21">difficulties</entity> are exacerbated by the <entity id="W06-1002.22">lack</entity> of comprehensive <entity id="W06-1002.23">lexical resources</entity>, especially for proper <entity id="W06-1002.24">nouns</entity>, and the <entity id="W06-1002.25">lack</entity> of a standardized orthography, especially in <entity id="W06-1002.26">Japanese</entity>. This <entity id="W06-1002.27">paper</entity> summarizes some of the major linguistic <entity id="W06-1002.28">issues</entity> in the <entity id="W06-1002.29">development</entity> <entity id="W06-1002.30">NLP applications</entity> that are dependent on <entity id="W06-1002.31">lexical resources</entity>, and discusses the central <entity id="W06-1002.32">role</entity> such <entity id="W06-1002.33">resources</entity> should play in enhancing the <entity id="W06-1002.34">accuracy</entity> of NLP <entity id="W06-1002.35">tools</entity>.
</abstract>


</text>

<text id="W06-1006"><title>
Multilingual <entity id="W06-1006.1">Collocation</entity> <entity id="W06-1006.2">Extraction</entity>: <entity id="W06-1006.3">Issues</entity> And Solutions
</title><abstract>
Although traditionally seen as a <entity id="W06-1006.4">language-independent</entity> <entity id="W06-1006.5">task</entity>, <entity id="W06-1006.6">collocation</entity> <entity id="W06-1006.7">extraction</entity> relies nowadays more and more on the linguistic preprocessing of <entity id="W06-1006.8">texts</entity> (e.g., lemmatization, <entity id="W06-1006.9">POS tagging</entity>, <entity id="W06-1006.10">chunking</entity> or <entity id="W06-1006.11">parsing</entity>) prior to the <entity id="W06-1006.12">application</entity> of <entity id="W06-1006.13">statistical</entity> measures. This <entity id="W06-1006.14">paper</entity> <entity id="W06-1006.15">provides</entity> a <entity id="W06-1006.16">language-oriented</entity> <entity id="W06-1006.17">review</entity> of the existing <entity id="W06-1006.18">extraction</entity> work. It points out several <entity id="W06-1006.19">language-specific</entity> <entity id="W06-1006.20">issues</entity> related to <entity id="W06-1006.21">extraction</entity> and <entity id="W06-1006.22">proposes</entity> a <entity id="W06-1006.23">strategy</entity> for coping with them. It then describes a hybrid <entity id="W06-1006.24">extraction system</entity> <entity id="W06-1006.25">based</entity> on a multilingual <entity id="W06-1006.26">parser</entity>. Finally, it presents a <entity id="W06-1006.27">case-study</entity> on the <entity id="W06-1006.28">performance</entity> of an <entity id="W06-1006.29">association</entity> measure across a <entity id="W06-1006.30">number</entity> of <entity id="W06-1006.31">languages</entity>.
</abstract>


</text>

<text id="W06-1303"><title><entity id="W06-1303.1">Building</entity> Effective <entity id="W06-1303.2">Question Answering</entity> Characters
</title><abstract>
In this <entity id="W06-1303.3">paper</entity>, we describe <entity id="W06-1303.4">methods</entity> for <entity id="W06-1303.5">building</entity> and <entity id="W06-1303.6">evaluation</entity> of limited <entity id="W06-1303.7">domain</entity> <entity id="W06-1303.8">question-answering</entity> characters. Several <entity id="W06-1303.9">classification</entity> <entity id="W06-1303.10">techniques</entity> are <entity id="W06-1303.11">tested</entity>, <entity id="W06-1303.12">including</entity> <entity id="W06-1303.13">text classification</entity> using <entity id="W06-1303.14">support vector machines</entity>, <entity id="W06-1303.15">language-model</entity> <entity id="W06-1303.16">based</entity> <entity id="W06-1303.17">retrieval</entity>, and <entity id="W06-1303.18">cross-language</entity> <entity id="W06-1303.19">information retrieval</entity> <entity id="W06-1303.20">techniques</entity>, with the latter having the highest <entity id="W06-1303.21">success</entity> <entity id="W06-1303.22">rate</entity>. We also <entity id="W06-1303.23">evaluated</entity> the <entity id="W06-1303.24">effect</entity> of <entity id="W06-1303.25">speech recognition</entity> <entity id="W06-1303.26">errors</entity> on <entity id="W06-1303.27">performance</entity> with <entity id="W06-1303.28">users</entity>, finding that <entity id="W06-1303.29">retrieval</entity> is <entity id="W06-1303.30">robust</entity> until <entity id="W06-1303.31">recognition</entity> <entity id="W06-1303.32">reaches</entity> over 50% WER.
</abstract>


</text>

</doc>