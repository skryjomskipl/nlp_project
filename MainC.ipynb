{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset from path: data/subtask11/1.1.train.text.xml\n",
      "Reading relations from path: data/subtask11/1.1.train.relations.txt\n",
      "Reading dataset from path: data/subtask11/1.1.test.text.xml\n",
      "Reading relations from path: data/subtask11/1.1.test.relations.txt\n",
      "Reading dataset from path: data/subtask11/1.1.test.text.xml\n",
      "Reading relations from path: data/subtask11/1.1.test.key.txt\n",
      "\n",
      "=> Training set\n",
      " -> X\n",
      "[[31, 12], [11, 7], [12, 12], [12, 12], [32, 2], [14, 12], [7, 12], [6, 6], [20, 13], [14, 12], [7, 12], [6, 27], [9, 9], [30, 7], [7, 29], [27, 27], [12, 14], [9, 9], [14, 13], [27, 27], [12, 12], [30, 30], [20, 30], [35, 8], [12, 12], [27, 27], [29, 7], [30, 7], [30, 30], [30, 30], [30, 30], [35, 12], [32, 32], [7, 7], [7, 7], [12, 12], [7, 30], [12, 12], [7, 13], [30, 12], [7, 12], [13, 12], [27, 27], [7, 12], [13, 21], [14, 13], [13, 13], [13, 12], [7, 13], [27, 27], [29, 29], [20, 27], [12, 30], [30, 7], [7, 7], [27, 20], [31, 12], [7, 7], [2, 2], [6, 6], [12, 13], [12, 12], [7, 13], [30, 12], [12, 29], [30, 30], [17, 27], [12, 13], [7, 13], [14, 12], [12, 12], [7, 12], [12, 12], [12, 12], [7, 13], [32, 2], [7, 7], [12, 12], [14, 12], [12, 12], [12, 12], [14, 12], [31, 31], [30, 27], [30, 30], [7, 12], [30, 30], [30, 30], [7, 14], [32, 7], [32, 32], [30, 30], [13, 12]]\n",
      " -> Y\n",
      "[1, 1, 4, 3, 4, 1, 3, 1, 1, 3, 4, 2, 3, 2, 1, 2, 3, 3, 1, 1, 2, 3, 1, 6, 3, 1, 1, 6, 1, 3, 3, 1, 1, 1, 1, 1, 5, 2, 4, 1, 3, 3, 6, 1, 6, 3, 3, 2, 2, 1, 1, 1, 1, 1, 4, 1, 6, 1, 4, 6, 1, 3, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 5, 3, 1, 2, 1, 4, 3, 4, 1, 1, 3, 1, 1, 1, 4, 1, 1, 4, 1, 4, 4]\n",
      "\n",
      "=> Testing set\n",
      " -> X\n",
      "[[12, 7], [7, 12], [12, 12], [32, 32], [32, 12], [27, 12], [31, 7], [13, 7], [20, 20], [32, 13], [29, 29], [7, 7], [7, 31], [7, 13], [13, 13], [32, 32], [32, 13], [20, 7], [13, 13], [2, 27], [32, 7], [2, 7], [30, 27], [13, 13], [6, 6]]\n",
      " -> Y\n",
      "[1 1 3 1 1 1 1 1 1 1 1 1 5 1 3 1 1 1 3 1 4 1 1 3 1]\n",
      "\n",
      "=> Results\n",
      "USAGE(P03-1068.1,P03-1068.2)\n",
      "USAGE(P03-1068.9,P03-1068.10)\n",
      "MODEL-FEATURE(P03-1070.9,P03-1070.10)\n",
      "USAGE(P03-1070.14,P03-1070.15,REVERSE)\n",
      "USAGE(P03-2036.4,P03-2036.6)\n",
      "USAGE(C04-1035.8,C04-1035.9)\n",
      "USAGE(C04-1035.15,C04-1035.16)\n",
      "USAGE(C04-1035.17,C04-1035.19,REVERSE)\n",
      "USAGE(C04-1035.20,C04-1035.22,REVERSE)\n",
      "USAGE(C04-1036.2,C04-1036.3,REVERSE)\n",
      "USAGE(C04-1036.8,C04-1036.9)\n",
      "USAGE(C04-1036.10,C04-1036.11)\n",
      "TOPIC(C04-1068.5,C04-1068.7)\n",
      "USAGE(C04-1068.9,C04-1068.10)\n",
      "MODEL-FEATURE(C04-1080.2,C04-1080.3)\n",
      "USAGE(C04-1080.10,C04-1080.11)\n",
      "USAGE(C04-1080.13,C04-1080.14)\n",
      "USAGE(C04-1096.1,C04-1096.2,REVERSE)\n",
      "MODEL-FEATURE(C04-1096.4,C04-1096.5)\n",
      "USAGE(C04-1096.12,C04-1096.13)\n",
      "PART_WHOLE(C04-1103.1,C04-1103.2)\n",
      "USAGE(C04-1103.4,C04-1103.5)\n",
      "USAGE(C04-1103.7,C04-1103.8)\n",
      "MODEL-FEATURE(C04-1103.9,C04-1103.10)\n",
      "USAGE(C04-1106.5,C04-1106.6)\n",
      "\n",
      "=> Metrics\n",
      "Accuracy: 48.0%\n",
      "F-Measure: 25.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brahmanacsw/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/brahmanacsw/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1076: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Entry point for testing\n",
    "#\n",
    "from dataset import *\n",
    "from common import *\n",
    "from modules import *\n",
    "import nltk\n",
    "#nltk.download()\n",
    "utils = Utils()\n",
    "train = Dataset('data/subtask11/1.1.train.text.xml', 'data/subtask11/1.1.train.relations.txt')\n",
    "train.read(utils)\n",
    "\n",
    "test = Dataset('data/subtask11/1.1.test.text.xml', 'data/subtask11/1.1.test.relations.txt', test_dataset = True)\n",
    "test.read(utils)\n",
    "\n",
    "test_key = Dataset('data/subtask11/1.1.test.text.xml', 'data/subtask11/1.1.test.key.txt')\n",
    "test_key.read(utils)\n",
    "\n",
    "# Prepare utilities\n",
    "utils = Utils()\n",
    "features = FeatureExtraction(utils)\n",
    "tfIdfCalculator=TfIdfCalculator(utils);\n",
    "\n",
    "# Enable features in this order: Przemek, Samantha, Chathuri\n",
    "features_state = [False, False, True]\n",
    "#features_state = [True, True, False]\n",
    "\n",
    "# Create training set\n",
    "features.set_dataset(train)\n",
    "tfIdfCalculator.set_dataset(train)\n",
    "s=tfIdfCalculator.calc_ifidf_data()\n",
    "train_X, train_Y = features.prepare_data(features_state)\n",
    "\n",
    "\n",
    "# Create test set\n",
    "features.set_dataset(test)\n",
    "tfIdfCalculator.set_dataset(test)\n",
    "s=tfIdfCalculator.calc_ifidf_data()\n",
    "test_X, test_Y = features.prepare_data(features_state, test_dataset = True)\n",
    "\n",
    "# TODO: You can provide development set by randomizing/shuffling training set.\n",
    "#       Then you need to alter of course code below.\n",
    "\n",
    "# Classify\n",
    "#clf = utils.get_classifier(\"Naive Bayes\")#Decision Tree, Naive Bayes, SVM\n",
    "#clf = utils.get_classifier(\"Decision Tree\")\n",
    "clf = utils.get_classifier(\"SVM\")\n",
    "clf = clf.fit(train_X, train_Y)\n",
    "test_Y = clf.predict(test_X)\n",
    "\n",
    "print(\"\\n=> Training set\")\n",
    "print(\" -> X\")\n",
    "print(train_X)\n",
    "print(\" -> Y\")\n",
    "print(train_Y)\n",
    "print(\"\\n=> Testing set\")\n",
    "print(\" -> X\")\n",
    "print(test_X)\n",
    "print(\" -> Y\")\n",
    "print(test_Y)\n",
    "\n",
    "# Preparing results\n",
    "print(\"\\n=> Results\")\n",
    "features.set_dataset(test)\n",
    "features.print_results(test_Y)\n",
    "\n",
    "# Compute accuracy\n",
    "features.set_dataset(test_key)\n",
    "test_key_Y = features.get_dataset_key()\n",
    "\n",
    "print(\"\\n=> Metrics\")\n",
    "print(\"Accuracy: \", round(utils.get_accuracy(test_key_Y, test_Y), 2), \"%\", sep = '')\n",
    "print(\"F-Measure: \", round(utils.get_fmeasure(test_key_Y, test_Y), 2), \"%\", sep = '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
